# ブースト会議での議論

## 1. 入力方法について

- ユーザ側もより多くのコンテキストをモデルに与えるために「なるべく確定しない」ような使い方をした方が良いのか、という議論があった
  - ブースト会議後に開発したzenz-v2では確定済みの文脈をコンテキストとして扱える仕組みを導入し、当座の入力については過去に確定してしまったコンテキストも見ながら変換できるようになった
  - ただし、早くに確定してしまうことによって生じる変換エラーについては、スペルチェッカーなどのポストエディットの仕組みを入れないと対策が難しいことがある（10月の進捗報告会で発見）

- 音声入力につなげることは可能であるか、という議論があった
  - ブースト会議時には「音声モダリティの取り扱いを考える必要がある」と述べるにとどまった
  - 現状も着手はしていないものの、最近のSpeech and Language Modelsの構成を参考にすれば、「個人最適な音声入力」も実現できると考えられる

- ミスタイプの修正は可能か、という議論があった
  - 程度問題だが、クエリの部分に揺らぎのあるデータを構築すれば可能である、と答えた

## 2. 競合へのアプローチについて

- ATOKに「勝利」したいか、どうすれば勝利できると思うか、という議論があった
  - オープンソースだという点で勝ち目がある可能性についてブースト会議では議論した
  - 連合学習によって勝利できる可能性に関して意見があった
  - 今回の発表では「分散型連合学習」に着目し未来の日本語入力の可能性に少しだけ触れます

## 3. アルゴリズムについて

- 推論速度に関する懸念が提起された
  - 投機的デコーディングに加え、「推論制約」という一入力あたりの推論回数を抑える仕組みにより、50ms以内での（ユーザの不快感を生じる閾値とされる時間）処理を実現し、リアルタイム性を保っている。興味があればアルファ版を試してほしい。
  - 今回の発表では前回触れなかった「負荷の均一化」という種類の最適化についても触れます
  - レポジトリ: https://github.com/ensan-hcl/azooKey-Desktop

## 4. 予測入力について

- 予測入力機能をラディカルに進化させたいとの議論があった。特に、入力するのではなく生成を基調とした日本語入力は実現できないか、というような意見があった
  - 面白い方向性であり、入力支援についてはそうしたラディカルな機能の実現を含め開発を進めている
  - ただし、この方向性が機能するためには予想を上回るContext-Awarenessが必要であるというのが、開発を進める中で得た所感。OSやアプリケーションとの連携を深めないと、「たまに便利な補完機能」を上回る「常に便利な補完機能」となるような性能を得ることは難しいかもしれない

## 関連リンク

### azooKey on macOS
https://github.com/ensan-hcl/azooKey-Desktop
有志の方によってWIndowとLinuxにも対応

### デモ動画
- 文脈を読んだ変換の動画: https://x.com/miwa_ensan/status/1818545939134791903
- 予測入力の動画: https://x.com/nya3_neko2/status/1843441177829486748
